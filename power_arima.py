# -*- coding: utf-8 -*-
"""power_Arima.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DrgkvxG07szZeYh0KzLkfLkMchYlFY8y
"""

#Import Libraries

import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller
import numpy as np
import math
import warnings
import pandas as pd

data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ExcelR Placements/Climate Connect Intern/power_actual.csv')

data.shape

data.info()

data['datetime'] = pd.to_datetime(data['datetime'])

data.head()

data.tail()

data.isna().sum()

data['Date'] = data.datetime.dt.date
data['Date'] = pd.to_datetime(data['Date'])

data = data.groupby('Date').mean().reset_index()

data.drop(data.columns[[1,2,3]], axis = 1,inplace=True)

data.set_index('Date', inplace=True) #set date as index

plt.xlabel("Date")
plt.ylabel("Power")
plt.title("production graph")
plt.plot(data['power'])

data.plot(style='k.')  #scatter_plot
plt.show()

plt.hist(data.power) #histogram

import seaborn as sns
sns.boxplot(data)

data.describe()

#dealing with Outlier
lower_bound= 0.1
upper_bound= 0.95
res = data.power.quantile([lower_bound,upper_bound])
res

true_index = (res.loc[lower_bound] < data.power.values) & (data.power.values < res.loc[upper_bound])
true_index

false_index = ~true_index
false_index

data.power[true_index]

data.power[false_index]

mid = np.median(data.power[true_index])
mid

data[false_index] = mid  #imputing outliers with median value.

data

plt.xlabel("Date")
plt.ylabel("Power")
plt.title("production graph")
plt.plot(data['power'])

data.plot(style='k.')  #scatter_plot
plt.show()

plt.hist(data.power)#histogram

"""#The values below lower extreme is not outlier because as per domain knowledge the lower values for solar power generation are during the sunrise and sunset."""

sns.boxplot(data)

from statsmodels.tsa.seasonal import seasonal_decompose
result = seasonal_decompose(data, model='multiplicative')
result.plot()
plt.show()

#ADF (Augmented Dickey-Fuller) Test to check data is stationary.
from statsmodels.tsa.stattools import adfuller
def test_stationarity(timeseries):
    #Determing rolling statistics
    rolmean = timeseries.rolling(12).mean()
    rolstd = timeseries.rolling(12).std()
    #Plot rolling statistics:
    plt.plot(timeseries, color='blue',label='Original')
    plt.plot(rolmean, color='red', label='Rolling Mean')
    plt.plot(rolstd, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean and Standard Deviation')
    plt.show(block=False)
    
    #perform dickey fuller test  
    print("Results of dickey fuller test")
    adft = adfuller(timeseries['power'],autolag='AIC')
    # output for dft will give us without defining what the values are.
    #hence we manually write what values does it explains using a for loop
    output = pd.Series(adft[0:4],index=['Test Statistics','p-value','No. of lags used','Number of observations used'])
    for key,values in adft[4].items():
        output['critical value (%s)'%key] =  values
    print(output)
    
test_stationarity(data)

df_log = np.log(data)
moving_avg = df_log.rolling(12).mean()
std_dev = df_log.rolling(12).std()
plt.plot(df_log)
plt.plot(moving_avg, color="red")
plt.plot(std_dev, color ="black")
plt.show()

df_log_moving_avg_diff = df_log-moving_avg
df_log_moving_avg_diff.dropna(inplace=True)

test_stationarity(df_log_moving_avg_diff)

weighted_average = df_log.ewm(halflife=12, min_periods=0,adjust=True).mean()

logScale_weightedMean = df_log-weighted_average
from pylab import rcParams
rcParams['figure.figsize'] = 10,6
test_stationarity(logScale_weightedMean)

df_log_diff = df_log - df_log.shift()
plt.title("Shifted timeseries")
plt.xlabel("Date")
plt.ylabel("power")
plt.plot(df_log_diff)
#Let us test the stationarity of our resultant series
df_log_diff.dropna(inplace=True)
test_stationarity(df_log_diff)

from chart_studio.plotly import plot_mpl
from statsmodels.tsa.seasonal import seasonal_decompose
result = seasonal_decompose(df_log, model='additive', freq = 12)
result.plot()
plt.show()
trend = result.trend
trend.dropna(inplace=True)
seasonality = result.seasonal
seasonality.dropna(inplace=True)
residual = result.resid
residual.dropna(inplace=True)
test_stationarity(residual)

from statsmodels.tsa.stattools import acf,pacf
# we use d value here(data_log_shift)
acf = acf(df_log_diff, nlags=15)
pacf= pacf(df_log_diff, nlags=15,method='ols')
#plot PACF
plt.subplot(121)
plt.plot(acf) 
plt.axhline(y=0,linestyle='-',color='blue')
plt.axhline(y=-1.96/np.sqrt(len(df_log_diff)),linestyle='--',color='black')
plt.axhline(y=1.96/np.sqrt(len(df_log_diff)),linestyle='--',color='black')
plt.title('Auto corellation function')
plt.tight_layout()
#plot ACF
plt.subplot(122)
plt.plot(pacf) 
plt.axhline(y=0,linestyle='-',color='blue')
plt.axhline(y=-1.96/np.sqrt(len(df_log_diff)),linestyle='--',color='black')
plt.axhline(y=1.96/np.sqrt(len(df_log_diff)),linestyle='--',color='black')
plt.title('Partially auto corellation function')
plt.tight_layout()

from statsmodels.tsa.arima_model import ARIMA
model = ARIMA(df_log, order=(3,1,3))
result_AR = model.fit(disp = 0)
plt.plot(df_log_diff)
plt.plot(result_AR.fittedvalues, color='red')
plt.title("sum of squares of residuals")
print('RSS : %f' %sum((result_AR.fittedvalues-df_log_diff["power"])**2))

result_AR.plot_predict(1,750)
x=result_AR.forecast(steps=200)